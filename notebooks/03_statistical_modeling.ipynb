{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Statistical Modeling: Claim Severity and Premium Prediction\n",
        "\n",
        "This notebook builds predictive models for:\n",
        "1. **Claim Severity Prediction**: Predict TotalClaims for policies with claims > 0\n",
        "2. **Premium Optimization**: Predict optimal premium values\n",
        "\n",
        "## Models to Implement\n",
        "- Linear Regression\n",
        "- Decision Trees\n",
        "- Random Forests\n",
        "- XGBoost\n",
        "\n",
        "## Evaluation Metrics\n",
        "- RMSE (Root Mean Squared Error)\n",
        "- R² (Coefficient of Determination)\n",
        "- MAE (Mean Absolute Error)\n",
        "- MAPE (Mean Absolute Percentage Error)\n",
        "\n",
        "## Model Interpretability\n",
        "- Feature Importance Analysis\n",
        "- SHAP (SHapley Additive exPlanations)\n",
        "- LIME (Local Interpretable Model-agnostic Explanations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "XGBoostError",
          "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/danielmituku/Documents/10Academy/week3/End-to-End-Insurance-Risk-Analytics-Predictive-Modeling/.venv/lib/python3.14/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <636BF463-1886-392D-B8B3-6011C44DCEE9> /Users/danielmituku/Documents/10Academy/week3/End-to-End-Insurance-Risk-Analytics-Predictive-Modeling/.venv/lib/python3.14/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libomp.dylib' (no such file), '/opt/homebrew/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libomp.dylib' (no such file)\"]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_insurance_data\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m REPORTS_DIR, MODELS_DIR\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_preparation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     prepare_claim_severity_data,\n\u001b[32m     19\u001b[39m     prepare_premium_prediction_data\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     train_linear_regression,\n\u001b[32m     23\u001b[39m     train_decision_tree,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     compare_models\n\u001b[32m     28\u001b[39m )\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterpretability\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     30\u001b[39m     get_feature_importance,\n\u001b[32m     31\u001b[39m     plot_feature_importance,\n\u001b[32m     32\u001b[39m     explain_with_shap,\n\u001b[32m     33\u001b[39m     plot_shap_summary\n\u001b[32m     34\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/10Academy/week3/End-to-End-Insurance-Risk-Analytics-Predictive-Modeling/src/modeling/__init__.py:10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Statistical and Machine Learning modeling modules.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_preparation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     prepare_claim_severity_data,\n\u001b[32m      5\u001b[39m     prepare_premium_prediction_data,\n\u001b[32m      6\u001b[39m     encode_categorical_features,\n\u001b[32m      7\u001b[39m     create_claim_probability_feature\n\u001b[32m      8\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     train_linear_regression,\n\u001b[32m     12\u001b[39m     train_decision_tree,\n\u001b[32m     13\u001b[39m     train_random_forest,\n\u001b[32m     14\u001b[39m     train_xgboost,\n\u001b[32m     15\u001b[39m     evaluate_model,\n\u001b[32m     16\u001b[39m     compare_models\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterpretability\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     get_feature_importance,\n\u001b[32m     21\u001b[39m     plot_feature_importance,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     explain_with_lime\n\u001b[32m     25\u001b[39m )\n\u001b[32m     27\u001b[39m __all__ = [\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# Data preparation\u001b[39;00m\n\u001b[32m     29\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mprepare_claim_severity_data\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexplain_with_lime\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     46\u001b[39m ]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/10Academy/week3/End-to-End-Insurance-Risk-Analytics-Predictive-Modeling/src/modeling/models.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeRegressor\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score, mean_absolute_error\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Tuple, Any\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/10Academy/week3/End-to-End-Insurance-Risk-Analytics-Predictive-Modeling/.venv/lib/python3.14/site-packages/xgboost/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     Booster,\n\u001b[32m     10\u001b[39m     DataIter,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     build_info,\n\u001b[32m     16\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/10Academy/week3/End-to-End-Insurance-Risk-Analytics-Predictive-Modeling/.venv/lib/python3.14/site-packages/xgboost/tracker.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, _deprecate_positional_args, make_jcargs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/10Academy/week3/End-to-End-Insurance-Risk-Analytics-Predictive-Modeling/.venv/lib/python3.14/site-packages/xgboost/core.py:308\u001b[39m\n\u001b[32m    304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m _LIB = \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    313\u001b[39m \n\u001b[32m    314\u001b[39m \u001b[33;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m        return value from API calls\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/10Academy/week3/End-to-End-Insurance-Risk-Analytics-Predictive-Modeling/.venv/lib/python3.14/site-packages/xgboost/core.py:270\u001b[39m, in \u001b[36m_load_lib\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[32m    269\u001b[39m         libname = os.path.basename(lib_paths[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[32m    271\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[33mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) could not be loaded.\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[33mLikely causes:\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[33m  * OpenMP runtime is not installed\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[33m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[33m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[33m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[33m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[32m    279\u001b[39m \n\u001b[32m    280\u001b[39m \u001b[33m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[32m    281\u001b[39m \n\u001b[32m    282\u001b[39m \u001b[33mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    284\u001b[39m         )\n\u001b[32m    285\u001b[39m     _register_log_callback(lib)\n\u001b[32m    287\u001b[39m     libver = _lib_version(lib)\n",
            "\u001b[31mXGBoostError\u001b[39m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/danielmituku/Documents/10Academy/week3/End-to-End-Insurance-Risk-Analytics-Predictive-Modeling/.venv/lib/python3.14/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <636BF463-1886-392D-B8B3-6011C44DCEE9> /Users/danielmituku/Documents/10Academy/week3/End-to-End-Insurance-Risk-Analytics-Predictive-Modeling/.venv/lib/python3.14/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libomp.dylib' (no such file), '/opt/homebrew/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libomp.dylib' (no such file)\"]\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "\n",
        "from src.data.load_data import load_insurance_data\n",
        "from src.utils.config import REPORTS_DIR, MODELS_DIR\n",
        "from src.modeling.data_preparation import (\n",
        "    prepare_claim_severity_data,\n",
        "    prepare_premium_prediction_data\n",
        ")\n",
        "from src.modeling.models import (\n",
        "    train_linear_regression,\n",
        "    train_decision_tree,\n",
        "    train_random_forest,\n",
        "    train_xgboost,\n",
        "    evaluate_model,\n",
        "    compare_models\n",
        ")\n",
        "from src.modeling.interpretability import (\n",
        "    get_feature_importance,\n",
        "    plot_feature_importance,\n",
        "    explain_with_shap,\n",
        "    plot_shap_summary\n",
        ")\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "%matplotlib inline\n",
        "\n",
        "# Create directories\n",
        "FIGURES_DIR = REPORTS_DIR / \"figures\"\n",
        "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = load_insurance_data()\n",
        "print(f\"Dataset loaded: {len(df):,} rows, {len(df.columns)} columns\")\n",
        "print(f\"\\nPolicies with claims: {len(df[df['TotalClaims'] > 0]):,}\")\n",
        "print(f\"Policies without claims: {len(df[df['TotalClaims'] == 0]):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 1: Claim Severity Prediction\n",
        "\n",
        "Predict TotalClaims for policies that have claims > 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for claim severity prediction\n",
        "X_train_sev, X_test_sev, y_train_sev, y_test_sev, feature_names_sev, preprocessor_sev = \\\n",
        "    prepare_claim_severity_data(df, target_col='TotalClaims', test_size=0.2)\n",
        "\n",
        "print(f\"Training set: {X_train_sev.shape[0]:,} samples, {X_train_sev.shape[1]} features\")\n",
        "print(f\"Test set: {X_test_sev.shape[0]:,} samples\")\n",
        "print(f\"\\nTarget (TotalClaims) statistics:\")\n",
        "print(f\"  Mean: {y_train_sev.mean():.2f} ZAR\")\n",
        "print(f\"  Median: {y_train_sev.median():.2f} ZAR\")\n",
        "print(f\"  Std: {y_train_sev.std():.2f} ZAR\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train all models for claim severity prediction\n",
        "models_sev = {}\n",
        "\n",
        "print(\"Training models for Claim Severity Prediction...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Linear Regression\n",
        "print(\"\\n1. Training Linear Regression...\")\n",
        "model_lr, train_metrics_lr = train_linear_regression(X_train_sev, y_train_sev)\n",
        "models_sev['Linear Regression'] = (model_lr, train_metrics_lr)\n",
        "test_metrics_lr = evaluate_model(model_lr, X_test_sev, y_test_sev)\n",
        "print(f\"   Test RMSE: {test_metrics_lr['rmse']:.2f}, Test R²: {test_metrics_lr['r2']:.4f}\")\n",
        "\n",
        "# Decision Tree\n",
        "print(\"\\n2. Training Decision Tree...\")\n",
        "model_dt, train_metrics_dt = train_decision_tree(X_train_sev, y_train_sev, max_depth=10)\n",
        "models_sev['Decision Tree'] = (model_dt, train_metrics_dt)\n",
        "test_metrics_dt = evaluate_model(model_dt, X_test_sev, y_test_sev)\n",
        "print(f\"   Test RMSE: {test_metrics_dt['rmse']:.2f}, Test R²: {test_metrics_dt['r2']:.4f}\")\n",
        "\n",
        "# Random Forest\n",
        "print(\"\\n3. Training Random Forest...\")\n",
        "model_rf, train_metrics_rf = train_random_forest(X_train_sev, y_train_sev, n_estimators=100)\n",
        "models_sev['Random Forest'] = (model_rf, train_metrics_rf)\n",
        "test_metrics_rf = evaluate_model(model_rf, X_test_sev, y_test_sev)\n",
        "print(f\"   Test RMSE: {test_metrics_rf['rmse']:.2f}, Test R²: {test_metrics_rf['r2']:.4f}\")\n",
        "\n",
        "# XGBoost\n",
        "print(\"\\n4. Training XGBoost...\")\n",
        "model_xgb, train_metrics_xgb = train_xgboost(X_train_sev, y_train_sev, n_estimators=100)\n",
        "models_sev['XGBoost'] = (model_xgb, train_metrics_xgb)\n",
        "test_metrics_xgb = evaluate_model(model_xgb, X_test_sev, y_test_sev)\n",
        "print(f\"   Test RMSE: {test_metrics_xgb['rmse']:.2f}, Test R²: {test_metrics_xgb['r2']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"All models trained successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all models\n",
        "comparison_sev = compare_models(models_sev, X_test_sev, y_test_sev)\n",
        "print(\"\\nModel Comparison - Claim Severity Prediction:\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_sev.to_string(index=False))\n",
        "\n",
        "# Identify best model\n",
        "best_model_sev = comparison_sev.loc[comparison_sev['Test_R2'].idxmax(), 'Model']\n",
        "print(f\"\\nBest Model (by R²): {best_model_sev}\")\n",
        "print(f\"  Test R²: {comparison_sev.loc[comparison_sev['Test_R2'].idxmax(), 'Test_R2']:.4f}\")\n",
        "print(f\"  Test RMSE: {comparison_sev.loc[comparison_sev['Test_R2'].idxmax(), 'Test_RMSE']:.2f} ZAR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2: Premium Prediction\n",
        "\n",
        "Predict optimal premium values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for premium prediction\n",
        "X_train_prem, X_test_prem, y_train_prem, y_test_prem, feature_names_prem, preprocessor_prem = \\\n",
        "    prepare_premium_prediction_data(df, target_col='TotalPremium', test_size=0.2)\n",
        "\n",
        "print(f\"Training set: {X_train_prem.shape[0]:,} samples, {X_train_prem.shape[1]} features\")\n",
        "print(f\"Test set: {X_test_prem.shape[0]:,} samples\")\n",
        "print(f\"\\nTarget (TotalPremium) statistics:\")\n",
        "print(f\"  Mean: {y_train_prem.mean():.2f} ZAR\")\n",
        "print(f\"  Median: {y_train_prem.median():.2f} ZAR\")\n",
        "print(f\"  Std: {y_train_prem.std():.2f} ZAR\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train all models for premium prediction\n",
        "models_prem = {}\n",
        "\n",
        "print(\"Training models for Premium Prediction...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Linear Regression\n",
        "print(\"\\n1. Training Linear Regression...\")\n",
        "model_lr_prem, train_metrics_lr_prem = train_linear_regression(X_train_prem, y_train_prem)\n",
        "models_prem['Linear Regression'] = (model_lr_prem, train_metrics_lr_prem)\n",
        "test_metrics_lr_prem = evaluate_model(model_lr_prem, X_test_prem, y_test_prem)\n",
        "print(f\"   Test RMSE: {test_metrics_lr_prem['rmse']:.2f}, Test R²: {test_metrics_lr_prem['r2']:.4f}\")\n",
        "\n",
        "# Decision Tree\n",
        "print(\"\\n2. Training Decision Tree...\")\n",
        "model_dt_prem, train_metrics_dt_prem = train_decision_tree(X_train_prem, y_train_prem, max_depth=10)\n",
        "models_prem['Decision Tree'] = (model_dt_prem, train_metrics_dt_prem)\n",
        "test_metrics_dt_prem = evaluate_model(model_dt_prem, X_test_prem, y_test_prem)\n",
        "print(f\"   Test RMSE: {test_metrics_dt_prem['rmse']:.2f}, Test R²: {test_metrics_dt_prem['r2']:.4f}\")\n",
        "\n",
        "# Random Forest\n",
        "print(\"\\n3. Training Random Forest...\")\n",
        "model_rf_prem, train_metrics_rf_prem = train_random_forest(X_train_prem, y_train_prem, n_estimators=100)\n",
        "models_prem['Random Forest'] = (model_rf_prem, train_metrics_rf_prem)\n",
        "test_metrics_rf_prem = evaluate_model(model_rf_prem, X_test_prem, y_test_prem)\n",
        "print(f\"   Test RMSE: {test_metrics_rf_prem['rmse']:.2f}, Test R²: {test_metrics_rf_prem['r2']:.4f}\")\n",
        "\n",
        "# XGBoost\n",
        "print(\"\\n4. Training XGBoost...\")\n",
        "model_xgb_prem, train_metrics_xgb_prem = train_xgboost(X_train_prem, y_train_prem, n_estimators=100)\n",
        "models_prem['XGBoost'] = (model_xgb_prem, train_metrics_xgb_prem)\n",
        "test_metrics_xgb_prem = evaluate_model(model_xgb_prem, X_test_prem, y_test_prem)\n",
        "print(f\"   Test RMSE: {test_metrics_xgb_prem['rmse']:.2f}, Test R²: {test_metrics_xgb_prem['r2']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"All models trained successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all models for premium prediction\n",
        "comparison_prem = compare_models(models_prem, X_test_prem, y_test_prem)\n",
        "print(\"\\nModel Comparison - Premium Prediction:\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_prem.to_string(index=False))\n",
        "\n",
        "# Identify best model\n",
        "best_model_prem = comparison_prem.loc[comparison_prem['Test_R2'].idxmax(), 'Model']\n",
        "print(f\"\\nBest Model (by R²): {best_model_prem}\")\n",
        "print(f\"  Test R²: {comparison_prem.loc[comparison_prem['Test_R2'].idxmax(), 'Test_R2']:.4f}\")\n",
        "print(f\"  Test RMSE: {comparison_prem.loc[comparison_prem['Test_R2'].idxmax(), 'Test_RMSE']:.2f} ZAR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Interpretability: Feature Importance Analysis\n",
        "\n",
        "Analyze which features are most influential in predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importance for best claim severity model\n",
        "best_sev_model_name = best_model_sev\n",
        "best_sev_model = models_sev[best_sev_model_name][0]\n",
        "\n",
        "importance_sev = get_feature_importance(best_sev_model, feature_names_sev)\n",
        "print(f\"\\nTop 10 Features for {best_sev_model_name} (Claim Severity):\")\n",
        "print(\"=\"*80)\n",
        "print(importance_sev.head(10).to_string(index=False))\n",
        "\n",
        "# Plot feature importance\n",
        "plot_feature_importance(\n",
        "    importance_sev,\n",
        "    top_n=10,\n",
        "    title=f\"Top 10 Feature Importance - {best_sev_model_name} (Claim Severity)\",\n",
        "    save_path=FIGURES_DIR / '10_feature_importance_claim_severity.png'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importance for best premium prediction model\n",
        "best_prem_model_name = best_model_prem\n",
        "best_prem_model = models_prem[best_prem_model_name][0]\n",
        "\n",
        "importance_prem = get_feature_importance(best_prem_model, feature_names_prem)\n",
        "print(f\"\\nTop 10 Features for {best_prem_model_name} (Premium Prediction):\")\n",
        "print(\"=\"*80)\n",
        "print(importance_prem.head(10).to_string(index=False))\n",
        "\n",
        "# Plot feature importance\n",
        "plot_feature_importance(\n",
        "    importance_prem,\n",
        "    top_n=10,\n",
        "    title=f\"Top 10 Feature Importance - {best_prem_model_name} (Premium Prediction)\",\n",
        "    save_path=FIGURES_DIR / '11_feature_importance_premium.png'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SHAP Analysis (for Best Model)\n",
        "\n",
        "Use SHAP to understand how individual features influence predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHAP analysis for best claim severity model\n",
        "print(f\"Generating SHAP explanations for {best_sev_model_name} (Claim Severity)...\")\n",
        "shap_result_sev = explain_with_shap(\n",
        "    best_sev_model,\n",
        "    X_test_sev[:100],  # Use sample for faster computation\n",
        "    feature_names_sev,\n",
        "    max_evals=100\n",
        ")\n",
        "\n",
        "if shap_result_sev:\n",
        "    plot_shap_summary(\n",
        "        shap_result_sev,\n",
        "        save_path=FIGURES_DIR / '12_shap_summary_claim_severity.png'\n",
        "    )\n",
        "    print(\"\\nSHAP analysis completed!\")\n",
        "else:\n",
        "    print(\"SHAP analysis not available. Install SHAP: pip install shap\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Business Recommendations\n",
        "\n",
        "Based on model performance and feature importance analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODELING SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. CLAIM SEVERITY PREDICTION:\")\n",
        "print(f\"   Best Model: {best_sev_model_name}\")\n",
        "print(f\"   Test R²: {comparison_sev.loc[comparison_sev['Model'] == best_sev_model_name, 'Test_R2'].values[0]:.4f}\")\n",
        "print(f\"   Test RMSE: {comparison_sev.loc[comparison_sev['Model'] == best_sev_model_name, 'Test_RMSE'].values[0]:.2f} ZAR\")\n",
        "print(f\"\\n   Top 5 Features:\")\n",
        "for idx, row in importance_sev.head(5).iterrows():\n",
        "    print(f\"     - {row['feature']}: {row['importance']:.4f}\")\n",
        "\n",
        "print(\"\\n2. PREMIUM PREDICTION:\")\n",
        "print(f\"   Best Model: {best_prem_model_name}\")\n",
        "print(f\"   Test R²: {comparison_prem.loc[comparison_prem['Model'] == best_prem_model_name, 'Test_R2'].values[0]:.4f}\")\n",
        "print(f\"   Test RMSE: {comparison_prem.loc[comparison_prem['Model'] == best_prem_model_name, 'Test_RMSE'].values[0]:.2f} ZAR\")\n",
        "print(f\"\\n   Top 5 Features:\")\n",
        "for idx, row in importance_prem.head(5).iterrows():\n",
        "    print(f\"     - {row['feature']}: {row['importance']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Business Recommendations will be documented in the final report.\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
